{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링한 초기 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각각 크롤링한 csv 불러오기\n",
    "df1=pd.read_csv(r'C:\\Users\\Playdata\\Desktop\\programers_cp949_1.csv', encoding='cp949')\n",
    "df2=pd.read_csv(r\"C:\\Users\\Playdata\\Desktop\\wanted_cp949_1.csv\", encoding='cp949')\n",
    "df3=pd.read_csv(r\"C:\\Users\\Playdata\\Desktop\\jumpit_cp949_1.csv\", encoding='cp949')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직무 기술 스택 묶어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직무&기술스택 보기\n",
    "def add_positions_from_csv(file_path, combined_position_stack):\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)  # 헤더 건너뛰기\n",
    "        for row in reader:\n",
    "            position = row[0]\n",
    "            stack_item = row[1]\n",
    "            if position in combined_position_stack:\n",
    "                combined_position_stack[position].add(stack_item)\n",
    "            else:\n",
    "                combined_position_stack[position] = {stack_item}\n",
    "    return combined_position_stack\n",
    "\n",
    "combined_position_stack = {}  \n",
    "\n",
    "# 세 개의 CSV 파일 합치기\n",
    "combined_position_stack = add_positions_from_csv(r\"C:\\Users\\Playdata\\Desktop\\position_stack1.csv\", combined_position_stack)\n",
    "combined_position_stack = add_positions_from_csv(r\"C:\\Users\\Playdata\\Desktop\\position_stack2.csv\", combined_position_stack)\n",
    "combined_position_stack = add_positions_from_csv(r\"C:\\Users\\Playdata\\Desktop\\position_stack3.csv\", combined_position_stack)\n",
    "\n",
    "#최종 저장\n",
    "directory = r'C:\\Users\\Playdata\\Desktop\\\\' \n",
    "\n",
    "filename1 = os.path.join(directory, 'combined_position_stack.csv')\n",
    "\n",
    "with open(filename1, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Position', 'Stack'])  # 헤더 작성\n",
    "    for position, stack in combined_position_stack.items():\n",
    "        for stack_item in stack:\n",
    "            writer.writerow([position, stack_item])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📌데이터 전처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 같은 공고 처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 프로그래머스 & 원티드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 살짝 전처리\n",
    "def preprocess_dataframe(df):\n",
    "    df['공고명'] = df['공고명'].str.replace('벡엔드', '백엔드')\n",
    "    df['회사명'] = df['회사명'].str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "    return df\n",
    "\n",
    "df1 = preprocess_dataframe(df1)\n",
    "df2 = preprocess_dataframe(df2)\n",
    "df3 = preprocess_dataframe(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 공고에 모두 있는 회사명 데이터 빼내기 filtered_df\n",
    "def preprocess_and_compare_links(df,intersection):\n",
    "    # 공통으로 있는 회사만 필터링\n",
    "    filtered_df = df[df['회사명'].isin(intersection)].copy() # Avoid SettingWithCopyWarning by explicitly creating a copy\n",
    "    # NaN인 기술스택을 '[]'로 대체\n",
    "    filtered_df.loc[filtered_df['기술스택'].apply(lambda x: isinstance(x, float)), '기술스택'] = filtered_df.loc[filtered_df['기술스택'].apply(lambda x: isinstance(x, float)), '기술스택'].apply(lambda x: '[]' if pd.isnull(x) else x)\n",
    "    # 공고명에서 '신입'과 ()로 둘러싸인 부분 삭제\n",
    "    filtered_df.loc[:, '공고명'] = filtered_df['공고명'].apply(lambda x: re.sub(r' \\(신입.*?\\)|신입|\\[신입.*?\\] |\\[코스닥상장사\\] |채용', '', x))\n",
    "    filtered_df.loc[:, '공고명'] = filtered_df['공고명'].apply(lambda x: re.sub(r'\\(신입/경력\\)', '', x))\n",
    "\n",
    "    # 중복되지 않은 데이터를 추출\n",
    "    df = df[~df['링크'].isin(filtered_df['링크'])]\n",
    "    \n",
    "    return df,filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df1,df2])\n",
    "intersection = pd.Series(list(set(df1['회사명'].unique()) & set(df2['회사명'].unique())))\n",
    "df, filtered_df = preprocess_and_compare_links(df, intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회사가 같고, 링크는 다르고, 한 공고문이 다른 공고문을 완전히 포함하고 있을 때 \n",
    "# 중복된 공고명을 가진 그룹 찾기\n",
    "def find_exact_matches(grouped, url_a, url_b):\n",
    "    exact_match_df = pd.DataFrame(columns=grouped.first().columns)\n",
    "    for _, group in grouped:\n",
    "        if len(group) > 1:\n",
    "            for i in range(len(group)):\n",
    "                a_group = group.iloc[i].copy() # copy() method to avoid SettingWithCopyWarning\n",
    "                for j in range(i + 1, len(group)):\n",
    "                    b_group = group.iloc[j].copy()\n",
    "                    if ((a_group['링크'].startswith(url_a) and b_group['링크'].startswith(url_b))\n",
    "                        or (a_group['링크'].startswith(url_b) and b_group['링크'].startswith(url_a))):\n",
    "                        if a_group['공고명'].replace(\" \", \"\") == b_group['공고명'].replace(\" \", \"\"):\n",
    "                            if a_group['기술스택'] != b_group['기술스택']:\n",
    "                                combined_tech_stack = set()\n",
    "\n",
    "                                if isinstance(a_group['기술스택'], str):\n",
    "                                    a_group['기술스택'] = ast.literal_eval(a_group['기술스택'])\n",
    "                                    for a_stack in a_group['기술스택']:\n",
    "                                        combined_tech_stack.add(a_stack)\n",
    "\n",
    "                                if isinstance(b_group['기술스택'], str):\n",
    "                                    b_group['기술스택'] = ast.literal_eval(b_group['기술스택'])\n",
    "                                    for b_stack in b_group['기술스택']:\n",
    "                                        combined_tech_stack.add(b_stack)\n",
    "                                    \n",
    "                                combined_tech_stack = list(combined_tech_stack) \n",
    "\n",
    "                                a_group['기술스택'] = combined_tech_stack\n",
    "                                b_group['기술스택'] = combined_tech_stack\n",
    "\n",
    "                            # Use pd.concat instead of DataFrame.append\n",
    "                            exact_match_df = pd.concat([exact_match_df, pd.DataFrame(a_group).T], ignore_index=True)\n",
    "                            exact_match_df = pd.concat([exact_match_df, pd.DataFrame(b_group).T], ignore_index=True)\n",
    "    return exact_match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포함관계인 공고문 찾기\n",
    "def find_included_matches(grouped, url_a, url_b):\n",
    "    included_df = pd.DataFrame(columns=grouped.first().columns)\n",
    "    for _, group in grouped:\n",
    "        if len(group) > 1:\n",
    "            for i in range(len(group)):\n",
    "                a_group = group.iloc[i].copy() # copy() method to avoid SettingWithCopyWarning\n",
    "                for j in range(i + 1, len(group)):\n",
    "                    b_group = group.iloc[j].copy()\n",
    "                    if ((a_group['링크'].startswith(url_a) and b_group['링크'].startswith(url_b))\n",
    "                        or (a_group['링크'].startswith(url_b) and b_group['링크'].startswith(url_a))):\n",
    "                        if (a_group['공고명'].replace(\" \", \"\") in b_group['공고명'].replace(\" \", \"\") \n",
    "                        or b_group['공고명'].replace(\" \", \"\") in a_group['공고명'].replace(\" \", \"\")):\n",
    "                            if a_group['기술스택'] != b_group['기술스택']:\n",
    "                                combined_tech_stack = set()\n",
    "\n",
    "                                if isinstance(a_group['기술스택'], str):\n",
    "                                    a_group['기술스택'] = ast.literal_eval(a_group['기술스택'])\n",
    "                                    for a_stack in a_group['기술스택']:\n",
    "                                        combined_tech_stack.add(a_stack)\n",
    "\n",
    "                                if isinstance(b_group['기술스택'], str):\n",
    "                                    b_group['기술스택'] = ast.literal_eval(b_group['기술스택'])\n",
    "                                    for b_stack in b_group['기술스택']:\n",
    "                                        combined_tech_stack.add(b_stack)\n",
    "\n",
    "                                combined_tech_stack = list(combined_tech_stack) \n",
    "\n",
    "                                a_group['기술스택'] = combined_tech_stack\n",
    "                                b_group['기술스택'] = combined_tech_stack\n",
    "\n",
    "                            # Use pd.concat instead of DataFrame.append\n",
    "                            included_df = pd.concat([included_df, pd.DataFrame(a_group).T], ignore_index=True)\n",
    "                            included_df = pd.concat([included_df, pd.DataFrame(b_group).T], ignore_index=True)\n",
    "    return included_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(filtered_df, exact_match_df, included_df, link_start):\n",
    "    solo_df = filtered_df[~filtered_df['링크'].isin(exact_match_df['링크'])]\n",
    "    solo_df = solo_df[~solo_df['링크'].isin(included_df['링크'])]\n",
    "\n",
    "    exact_match_df['기술스택'] = exact_match_df['기술스택'].apply(lambda x: str(x))\n",
    "    included_df['기술스택'] = included_df['기술스택'].apply(lambda x: str(x))\n",
    "\n",
    "    duplicates_df = pd.merge(exact_match_df, included_df, how='outer')\n",
    "\n",
    "    duplicates_df = duplicates_df[duplicates_df['링크'].str.startswith(link_start)]\n",
    "\n",
    "    # solo_df를 더함\n",
    "    final_df = pd.concat([df, solo_df], ignore_index=True)\n",
    "\n",
    "    # duplicates_df를 더함\n",
    "    final_df = pd.concat([final_df, duplicates_df], ignore_index=True)\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = filtered_df.groupby('회사명')\n",
    "exact_match_df = find_exact_matches(grouped, 'https://programmers.co.kr', 'https://www.wanted.co.kr')\n",
    "included_df = find_included_matches(grouped, 'https://programmers.co.kr', 'https://www.wanted.co.kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_wanted_df = process_df(filtered_df, exact_match_df, included_df, 'https://programmers.co.kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>공고명</th>\n",
       "      <th>회사명</th>\n",
       "      <th>직무</th>\n",
       "      <th>마감일</th>\n",
       "      <th>근무지</th>\n",
       "      <th>기술스택</th>\n",
       "      <th>링크</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>저작권 보호 서비스 개발</td>\n",
       "      <td>두다지</td>\n",
       "      <td>백엔드, 데이터 엔지니어</td>\n",
       "      <td>상시 채용</td>\n",
       "      <td>서울 서초구 매헌로 16, (양재동) 1206호 두다지</td>\n",
       "      <td>['Docker', 'Python', 'Kubernetes']</td>\n",
       "      <td>https://programmers.co.kr/job_positions/18147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>이러닝 웹 솔루션 개발자</td>\n",
       "      <td>Xinics</td>\n",
       "      <td>백엔드, 프론트엔드, 웹개발</td>\n",
       "      <td>상시 채용</td>\n",
       "      <td>서울특별시 구로구 디지털로31길 53, 1101호(구로동, 이엔씨벤처드림타워5차)</td>\n",
       "      <td>['HTML', 'CSS', 'JavaScript', 'React', 'PHP']</td>\n",
       "      <td>https://programmers.co.kr/job_positions/1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>백엔드 엔지니어 (Python)</td>\n",
       "      <td>데이터비</td>\n",
       "      <td>백엔드</td>\n",
       "      <td>상시 채용</td>\n",
       "      <td>서울 마포구 백범로31길 21, (공덕동) 404호</td>\n",
       "      <td>['Python', 'Redis', 'SQL']</td>\n",
       "      <td>https://programmers.co.kr/job_positions/17780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>백엔드 엔지니어 (NodeJS)</td>\n",
       "      <td>데이터비</td>\n",
       "      <td>백엔드</td>\n",
       "      <td>상시 채용</td>\n",
       "      <td>서울 마포구 백범로31길 21, (공덕동) 404호</td>\n",
       "      <td>['Node.js', 'Git']</td>\n",
       "      <td>https://programmers.co.kr/job_positions/17779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>C# 개발자</td>\n",
       "      <td>넥서스커뮤니티</td>\n",
       "      <td>백엔드</td>\n",
       "      <td>상시 채용</td>\n",
       "      <td>서울 영등포구 여의대로 108, (여의도동) 파크원 타워2 19F</td>\n",
       "      <td>['C#', 'MariaDB']</td>\n",
       "      <td>https://programmers.co.kr/job_positions/4351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>30</td>\n",
       "      <td>클라우드EDI 서비스 개발자</td>\n",
       "      <td>인스피언</td>\n",
       "      <td>백엔드</td>\n",
       "      <td>상시 채용</td>\n",
       "      <td>서울특별시 금천구 벚꽃로 278, SJ테크노빌 1309호</td>\n",
       "      <td>['Java', 'Spring']</td>\n",
       "      <td>https://programmers.co.kr/job_positions/13713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>212</td>\n",
       "      <td>Cloud 운영 개발</td>\n",
       "      <td>지니언스</td>\n",
       "      <td>DevOps</td>\n",
       "      <td>상시 채용</td>\n",
       "      <td>경기도 안양시 동안구 벌말로 66 평촌역 하이필드 지식산업센터 A동 12층</td>\n",
       "      <td>['MySQL', 'AWS', 'Docker', 'Kubernetes', 'Node...</td>\n",
       "      <td>https://programmers.co.kr/job_positions/17741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>63</td>\n",
       "      <td>Junior Backend Engineer</td>\n",
       "      <td>트릿지</td>\n",
       "      <td>백엔드, 웹개발, 데이터 엔지니어</td>\n",
       "      <td>상시 채용</td>\n",
       "      <td>서울특별시 서초구 방배로 226, 2, 4, 5, 6, 별관2층(방배동, 넥센강남타워)</td>\n",
       "      <td>['MySQL', 'Docker', 'Django', 'Python', 'Node....</td>\n",
       "      <td>https://programmers.co.kr/job_positions/15444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>69</td>\n",
       "      <td>Junior Data Engineer</td>\n",
       "      <td>트릿지</td>\n",
       "      <td>백엔드, 데이터 엔지니어</td>\n",
       "      <td>상시 채용</td>\n",
       "      <td>서울특별시 서초구 방배로 226, 2, 4, 5, 6, 별관2층(방배동, 넥센강남타워)</td>\n",
       "      <td>['Node.js', 'Django', 'Kafka', 'Hadoop', 'Pyth...</td>\n",
       "      <td>https://programmers.co.kr/job_positions/14660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>70</td>\n",
       "      <td>Data Acquisition Engineer</td>\n",
       "      <td>트릿지</td>\n",
       "      <td>백엔드, 데이터 엔지니어</td>\n",
       "      <td>상시 채용</td>\n",
       "      <td>서울특별시 서초구 방배로 226, 2, 4, 5, 6, 별관2층(방배동, 넥센강남타워)</td>\n",
       "      <td>['Docker', 'Django', 'Python', 'Node.js', 'SQL']</td>\n",
       "      <td>https://programmers.co.kr/job_positions/14657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>823 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                        공고명      회사명                  직무    마감일   \n",
       "0            0              저작권 보호 서비스 개발      두다지       백엔드, 데이터 엔지니어  상시 채용  \\\n",
       "1            4              이러닝 웹 솔루션 개발자   Xinics     백엔드, 프론트엔드, 웹개발  상시 채용   \n",
       "2            5          백엔드 엔지니어 (Python)     데이터비                 백엔드  상시 채용   \n",
       "3            6          백엔드 엔지니어 (NodeJS)     데이터비                 백엔드  상시 채용   \n",
       "4            7                     C# 개발자  넥서스커뮤니티                 백엔드  상시 채용   \n",
       "..         ...                        ...      ...                 ...    ...   \n",
       "818         30            클라우드EDI 서비스 개발자     인스피언                 백엔드  상시 채용   \n",
       "819        212                Cloud 운영 개발     지니언스              DevOps  상시 채용   \n",
       "820         63   Junior Backend Engineer       트릿지  백엔드, 웹개발, 데이터 엔지니어  상시 채용   \n",
       "821         69       Junior Data Engineer      트릿지       백엔드, 데이터 엔지니어  상시 채용   \n",
       "822         70  Data Acquisition Engineer      트릿지       백엔드, 데이터 엔지니어  상시 채용   \n",
       "\n",
       "                                                  근무지   \n",
       "0                      서울 서초구 매헌로 16, (양재동) 1206호 두다지  \\\n",
       "1       서울특별시 구로구 디지털로31길 53, 1101호(구로동, 이엔씨벤처드림타워5차)   \n",
       "2                        서울 마포구 백범로31길 21, (공덕동) 404호   \n",
       "3                        서울 마포구 백범로31길 21, (공덕동) 404호   \n",
       "4                서울 영등포구 여의대로 108, (여의도동) 파크원 타워2 19F   \n",
       "..                                                ...   \n",
       "818                   서울특별시 금천구 벚꽃로 278, SJ테크노빌 1309호   \n",
       "819         경기도 안양시 동안구 벌말로 66 평촌역 하이필드 지식산업센터 A동 12층   \n",
       "820  서울특별시 서초구 방배로 226, 2, 4, 5, 6, 별관2층(방배동, 넥센강남타워)   \n",
       "821  서울특별시 서초구 방배로 226, 2, 4, 5, 6, 별관2층(방배동, 넥센강남타워)   \n",
       "822  서울특별시 서초구 방배로 226, 2, 4, 5, 6, 별관2층(방배동, 넥센강남타워)   \n",
       "\n",
       "                                                  기술스택   \n",
       "0                   ['Docker', 'Python', 'Kubernetes']  \\\n",
       "1        ['HTML', 'CSS', 'JavaScript', 'React', 'PHP']   \n",
       "2                           ['Python', 'Redis', 'SQL']   \n",
       "3                                   ['Node.js', 'Git']   \n",
       "4                                    ['C#', 'MariaDB']   \n",
       "..                                                 ...   \n",
       "818                                 ['Java', 'Spring']   \n",
       "819  ['MySQL', 'AWS', 'Docker', 'Kubernetes', 'Node...   \n",
       "820  ['MySQL', 'Docker', 'Django', 'Python', 'Node....   \n",
       "821  ['Node.js', 'Django', 'Kafka', 'Hadoop', 'Pyth...   \n",
       "822   ['Docker', 'Django', 'Python', 'Node.js', 'SQL']   \n",
       "\n",
       "                                                링크  \n",
       "0    https://programmers.co.kr/job_positions/18147  \n",
       "1     https://programmers.co.kr/job_positions/1207  \n",
       "2    https://programmers.co.kr/job_positions/17780  \n",
       "3    https://programmers.co.kr/job_positions/17779  \n",
       "4     https://programmers.co.kr/job_positions/4351  \n",
       "..                                             ...  \n",
       "818  https://programmers.co.kr/job_positions/13713  \n",
       "819  https://programmers.co.kr/job_positions/17741  \n",
       "820  https://programmers.co.kr/job_positions/15444  \n",
       "821  https://programmers.co.kr/job_positions/14660  \n",
       "822  https://programmers.co.kr/job_positions/14657  \n",
       "\n",
       "[823 rows x 8 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_wanted_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 점핏까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df 합치기\n",
    "df = pd.concat([pro_wanted_df, df3])\n",
    "# df3의 근무지 불필요한 요소 제거\n",
    "df['근무지'] = df['근무지'].str.replace('\\n·', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = pd.Series(list(set(pro_wanted_df['회사명'].unique()) & set(df3['회사명'].unique())))\n",
    "\n",
    "df,filtered_df=preprocess_and_compare_links(df,intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회사가 같고, 링크는 다르고, 한 공고문이 다른 공고문을 완전히 포함하고 있을 때 \n",
    "# 중복된 공고명을 가진 그룹 찾기\n",
    "grouped = filtered_df.groupby('회사명')\n",
    "\n",
    "# 완전히 일치하는 경우를 찾는 코드\n",
    "exact_match_df = pd.DataFrame(columns=filtered_df.columns)\n",
    "exact_match_df = pd.concat([exact_match_df, find_exact_matches(grouped, 'https://programmers.co.kr', 'https://www.jumpit.co.kr')])\n",
    "exact_match_df = pd.concat([exact_match_df, find_exact_matches(grouped, 'https://www.wanted.co.kr', 'https://www.jumpit.co.kr')])\n",
    "\n",
    "# 포함관계인 경우를 찾는 코드\n",
    "included_df = pd.DataFrame(columns=filtered_df.columns)\n",
    "included_df = pd.concat([included_df, find_included_matches(grouped, 'https://programmers.co.kr', 'https://www.jumpit.co.kr')])\n",
    "included_df = pd.concat([included_df, find_included_matches(grouped, 'https://www.wanted.co.kr', 'https://www.jumpit.co.kr')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = process_df(filtered_df, exact_match_df, included_df, 'https://www.jumpit.co.kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1014"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_df.to_csv(r'C:\\Users\\Playdata\\Desktop\\final_df.csv', index=True, encoding='cp949')\n",
    "len(final_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직무 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_df\n",
    "df['직무'] = df['직무'].str.split(', ')\n",
    "\n",
    "# 웹개발 하나만 있는 경우\n",
    "df['직무'] = df['직무'].apply(lambda x: [\"프론트엔드\", \"백엔드\"] if isinstance(x, list) and x == [\"웹개발\"] else x)\n",
    "\n",
    "# 웹개발이 포함되어 있는 경우 웹개발을 삭제\n",
    "# df['직무'] = df['직무'].apply(lambda x: [job for job in x if job != \"웹개발\"])\n",
    "df['직무'] = df['직무'].apply(lambda x: [job for job in x if job != \"웹개발\"] if isinstance(x, list) else [])\n",
    "\n",
    "\n",
    "df.to_csv(r'C:\\Users\\Playdata\\Desktop\\df_pos.csv', index=False, encoding='cp949')\n",
    "df=pd.read_csv(r'C:\\Users\\Playdata\\Desktop\\df_pos.csv', encoding='cp949')\n",
    "\n",
    "df['직무'] = df['직무'].str.replace(\"'\", '\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기술스택 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where(condition, x, y)를 활용해서 condition이 참일 경우 x를, 아닌 경우 y로!\n",
    "df['기술스택'] = df['기술스택'].str.replace(\"'\", '\"')\n",
    "df['기술스택'] = np.where((df['기술스택'].isnull()) | (df['기술스택'] == \"[]\"), \"\"\"[\"\"]\"\"\", df['기술스택'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 마감일 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마감일 전처리 \n",
    "df['마감일'] = df['마감일'].str.replace('상시', '상시 채용')\n",
    "df['마감일'] = df['마감일'].str.replace('채용 채용', '채용')\n",
    "df['마감일'] = df['마감일'].fillna('상시 채용')\n",
    "\n",
    "# 날짜 형식 2023-04-12\n",
    "def format_date(date_str):\n",
    "    if date_str.startswith('상시 채용'):\n",
    "        return date_str\n",
    "#     elif date_str.startswith('상시'):\n",
    "#         return date_str\n",
    "    elif ':' in date_str:\n",
    "        date_obj = datetime.datetime.strptime(date_str, '%y년 %m월 %d일 %H:%M까지')\n",
    "        formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "        return formatted_date\n",
    "    else:\n",
    "        return date_str\n",
    "\n",
    "df['마감일'] = df['마감일'].apply(format_date)\n",
    "\n",
    "# # 날짜 형식 2023-04-12 00:00\n",
    "# import datetime\n",
    "\n",
    "# def format_date(date_str):\n",
    "#     if date_str.startswith('상시 채용'):\n",
    "#         return date_str\n",
    "#     elif ':' in date_str:\n",
    "#         date_obj = datetime.datetime.strptime(date_str, '%y년 %m월 %d일 %H:%M까지')\n",
    "#         formatted_date = date_obj.strftime('%Y-%m-%d %H:%M')\n",
    "#         return formatted_date\n",
    "#     else:\n",
    "#         date_obj = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "#         formatted_date = date_obj.strftime('%Y-%m-%d') + ' 24:00'\n",
    "#         return formatted_date\n",
    "\n",
    "# df['마감일'] = df['마감일'].apply(format_date)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 근무지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['근무지'] = df['근무지'].str.replace('주소 ', '')\n",
    "df['근무지'] = df['근무지'].str.replace('대한민국 ', '')\n",
    "df['근무지'] = df['근무지'].str.replace('서울특별시', '서울')\n",
    "df['근무지'] = df['근무지'].str.replace('서울시', '서울')\n",
    "df['근무지'] = df['근무지'].str.replace('경기도', '경기')\n",
    "df['근무지'] = df['근무지'].str.replace('제주특별자치도', '제주')\n",
    "df['근무지'] = df['근무지'].str.replace('제주특별자치도', '제주')\n",
    "df['근무지'] = df['근무지'].str.replace('울산광역시', '울산')\n",
    "df['근무지'] = df['근무지'].str.replace('경상북도', '경북')\n",
    "df['근무지'] = df['근무지'].str.replace('부산광역시', '부산')\n",
    "df['근무지'] = df['근무지'].str.replace('인천광역시', '인천')\n",
    "df['근무지'] = df['근무지'].str.replace('대전시', '대전')\n",
    "df['근무지'] = df['근무지'].str.replace('대전광역시', '대전')\n",
    "df['근무지'] = df['근무지'].str.replace('대구광역시', '대구')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 경기', '경기')\n",
    "df['근무지'] = df['근무지'].str.replace('전라남도', '전남')\n",
    "df['근무지'] = df['근무지'].str.replace('인천시', '인천')\n",
    "\n",
    "\n",
    "# 따로 열어보고 이상한 것 적는 곳\n",
    "df['근무지'] = df['근무지'].str.replace('Level ', '')\n",
    "df['근무지'] = df['근무지'].str.replace('입니다', '')\n",
    "df['근무지'] = df['근무지'].str.replace('입니다', '')\n",
    "df['근무지'] = df['근무지'].str.replace('대구 대전', '대전')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 06237', '')\n",
    "df['근무지'] = df['근무지'].str.replace(' 서울', '서울')\n",
    "df['근무지'] = df['근무지'].str.replace(r'서울 \\(06159\\)\\s*', '')\n",
    "df['근무지'] = df['근무지'].str.replace(r'서울 13449\\)\\s*', '')\n",
    "df['근무지'] = df['근무지'].str.replace(r'\\(07807\\)\\s*', '')\n",
    "df['근무지'] = df['근무지'].str.replace(r'\\(08380\\)\\s*', '')\n",
    "df['근무지'] = df['근무지'].str.replace(r'\\(06159\\)\\s*', '')\n",
    "df['근무지'] = df['근무지'].str.replace(r'\\[본사\\]\\s*', '')\n",
    "df['근무지'] = df['근무지'].str.replace('\\n·', '')\n",
    "df['근무지'] = df['근무지'].str.replace(r'^\\(\\d+\\)\\s*', '', regex=True)\n",
    "df['근무지'] = df['근무지'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "df['근무지'] = df['근무지'].str.replace('연남로13길9', '서울 마포구 연남로13길9', regex=True)\n",
    "df['근무지'] = df['근무지'].str.replace('광주 광주광역시', '광주')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 논현로', '서울 강남구 논현로')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 왕십리로', '서울 성동구 왕십리로')\n",
    "# df['근무지'] = df['근무지'].str.replace('서울 대치로', '')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 서초동', '서울 서초구 서초동')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 마포대로', '서울 마포구 마포대로')\n",
    "# df['근무지'] = df['근무지'].str.replace('서울 강남대로', '')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 반포대로', '서울 서초구 반포대로')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 원격 근무', '원격 근무')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 개포로', '서울 강남구 개포로')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 삼성로', '서울 강남구 삼성로')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 여의도', '서울 영등포구 여의도동')\n",
    "df['근무지'] = df['근무지'].str.replace('서울서울', '서울')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 선릉로', '서울 강남구 선릉로')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 테헤란로', '서울 강남구 테헤란로')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 삼성동', '서울 강남구 삼성동')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 양재동', '서울 서초구 양재동')\n",
    "df['근무지'] = df['근무지'].str.replace('경기 금토로', '경기 성남시 수정구 금토로')\n",
    "df['근무지'] = df['근무지'].str.replace('대전 가정북로', '대전 유성구 가정북로')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 강남대로 156', '서울 서초구 강남대로 156')\n",
    "df['근무지'] = df['근무지'].str.replace('경기 판교', '경기 성남시 분당구 판교동')\n",
    "df['근무지'] = df['근무지'].str.replace('대구 대구시내', '대구 중구 동성로')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 양화로', '서울 마포구 양화로')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 발산역', '서울 강서구 마곡동')\n",
    "df['근무지'] = df['근무지'].str.replace('서울 양재역', '서울 서초구 양재역')\n",
    "# '근무지' 컬럼의 데이터 형식 변경\n",
    "df.loc[df['근무지'].str.contains('Seoul, Republic of Korea', na=False), '근무지'] = None\n",
    "df.loc[df['근무지'].str.contains('서울 대치로 223', na=False), '근무지'] = None\n",
    "df.loc[df['근무지'].str.contains('원격 근무', na=False), '근무지'] = None\n",
    "df.loc[df['근무지'].str.contains('onetkorea137@gmail.com', na=False), '근무지'] = None\n",
    "\n",
    "df.dropna(subset=['근무지'], inplace=True)  # 결측치 가진 데이터 삭제\n",
    "df['근무지'] = df['근무지'].astype(str)  # 데이터 타입을 문자열로 변환\n",
    "\n",
    "\n",
    "df['근무지'] = df['근무지'].apply(lambda x: x.split(' ', 1)[1] if len(x.split(' ')) > 1 and x.split(' ')[0] == x.split(' ')[1] else x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회사 평점 컬럼 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xinics 3.8\n",
      "스와치온 3.3\n",
      "바텍 네트웍스 1.6\n",
      "알로카도스 0.0\n",
      "새론솔루션 0.0\n",
      "업스테이지 2.0\n",
      "웰트 3.4\n"
     ]
    }
   ],
   "source": [
    "# 회사명 중복값없이 리스트로 받기\n",
    "company_list=df['회사명'].unique().tolist()\n",
    "\n",
    "# 회사명과 평점으로 구성된 데이터 프레임\n",
    "company_star_df = pd.DataFrame(columns=['회사명', '평점'])\n",
    "\n",
    "# 크롤링 시작\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get('https://www.jobplanet.co.kr/search?query=+&category=search_new&search_keyword_hint_id=&_rs_con=seach&_rs_act=keyword_search')\n",
    "time.sleep(3)  # 3초 동안 대기\n",
    "\n",
    "for company in company_list:\n",
    "    # 검색 버튼 누르기\n",
    "    input_button = driver.find_element(By.XPATH, '//*[@id=\"search_bar_search_query\"]')\n",
    "    input_button.send_keys(company)\n",
    "    time.sleep(2)\n",
    "    star=0.0\n",
    "\n",
    "    elements = driver.find_elements(By.CSS_SELECTOR, 'ul > li.company')\n",
    "    if len(elements)==0:\n",
    "        pass\n",
    "    else:\n",
    "        submit_button=driver.find_element(By.CSS_SELECTOR, '#search_form > div > button')\n",
    "        submit_button.click()\n",
    "        time.sleep(2)  # 2초 동안 대기\n",
    "        if len(elements)==1:\n",
    "            star=driver.find_element(By.XPATH,'//*[@id=\"mainContents\"]/div[1]/div/div[2]/div[1]/div/span[3]').text        \n",
    "        else:\n",
    "            cards = driver.find_elements(By.CLASS_NAME, 'result_card')\n",
    "            for card in cards:\n",
    "                jp_company = card.text.split()[0].replace(\"(주)\", \"\")\n",
    "                if company == jp_company:\n",
    "                    star = card.text.split()[2]\n",
    "                    break\n",
    "\n",
    "    print(company,star)    \n",
    "    company_star_df.loc[len(company_star_df)] = [company, star]\n",
    "    # 검색창 지우기\n",
    "    input_button = driver.find_element(By.XPATH, '//*[@id=\"search_bar_search_query\"]')  # input_button 웹 요소를 다시 찾음\n",
    "    input_button.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(company_star_df, on='회사명', how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지역 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['지역']=df['근무지'].apply(lambda address: \" \".join(address.split(\" \")[:2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터프레임 깔끔하게 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['공고명','회사명','직무','마감일','근무지','기술스택','링크','평점','지역']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\Playdata\\Desktop\\final_true.csv', index=True, encoding='cp949')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
