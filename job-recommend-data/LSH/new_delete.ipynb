{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 df 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(r'C:\\Users\\Playdata\\Desktop\\programers_cp949_1.csv', encoding='cp949')\n",
    "df2=pd.read_csv(r\"C:\\Users\\Playdata\\Desktop\\wanted_cp949_1.csv\", encoding='cp949')\n",
    "df3=pd.read_csv(r\"C:\\Users\\Playdata\\Desktop\\jumpit_cp949_1.csv\", encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=[df1,df2, df3]\n",
    "df=pd.concat(df)\n",
    "df=df[['공고명', '회사명', '직무', '마감일', '근무지', '기술스택', '링크']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 공고가 들어가있는 링크 전체 리스트\n",
    "link_set = set(df['링크'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now_df=pd.read_csv(r'C:\\Users\\Playdata\\Desktop\\final_true_address.csv', encoding='cp949')\n",
    "now_df=now_df[['공고명', '회사명', '직무', '마감일', '근무지', '기술스택', '링크','평점','지역']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 공고 판별\n",
    "new_df=pd.DataFrame(columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#삭제되는 공고 판별\n",
    "delete_df = pd.DataFrame(columns=['공고명', '회사명', '직무', '마감일', '근무지', '기술스택', '링크', '평점'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 가지고 있는 공고\n",
    "present_set = set()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직무함수\n",
    "def classify_position(position):\n",
    "    if position in ['머신러닝', '인공지능', '머신러닝 엔지니어']:\n",
    "        return 'AI/ML'\n",
    "    elif position in ['웹 개발자','웹 풀스택']:\n",
    "        return '웹개발'\n",
    "    elif position in ['데이터 엔지니어','데이터 엔지니어링','빅데이터 엔지니어','BI 엔지니어']:\n",
    "        return '데이터 엔지니어'\n",
    "    elif position in ['데브옵스','DevOps/시스템 관리자']:\n",
    "        return 'DevOps'\n",
    "    elif position in ['서버/백엔드','PHP 개발자','루비온레일즈 개발자', '서버 개발자', '자바 개발자', 'C,C++ 개발자','파이썬 개발자','Node.js 개발자','DBA']:\n",
    "        return '백엔드'\n",
    "    elif position in ['프론트엔드', '프론트엔드 개발자']:\n",
    "        return '프론트엔드'\n",
    "    elif position in ['안드로이드', '안드로이드 개발자', 'iOS', 'iOS 개발자' ]:\n",
    "        return '모바일'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기술함수\n",
    "def classify_skill(skill):\n",
    "    if skill in [ 'AWS','AWS Alexa','AWS Amplify','AWS CloudFront','AWS DynamoDB','AWS EC2','AWS ECS','AWS EKS','AWS Lambda',\n",
    "                 'AWS RDS','AWS S3','AWS Serverless Application Repository','AWS Simple Notification Service(AWS SNS)',\n",
    "                 'AWS Simple Queue Service(AWS SQS)','Amazon Web Service','Amazon Web Services(AWS)','AWS App Mesh',\n",
    "                 'AWS Cloud Development Kit','AWS CodeCommit','AWS IoT Device Management','AWS Shell','Amazon API Gateway',\n",
    "                 'Amazon CloudFront','Amazon Connect','Amazon DynamoDB','Amazon EC2','Amazon EKS','Amazon RDS','Amazon RDS for PostgreSQL',\n",
    "                 'Amazon Route 53','Amazon S3','aws','amazon dynamodb','Amazon SQS', 'Yocto','aws batch', 'EC2' ,'EMR']:\n",
    "        return 'AWS'\n",
    "    elif skill in ['Kotlin','Android','Android Studio','Android OS','Android SDK', 'android os']:\n",
    "        return 'Kotlin'\n",
    "    elif skill in ['Angular','AngularJS','angular 2','Angular 2']:\n",
    "        return 'Angular'\n",
    "    elif skill in ['Apache','Apache HTTP Server','Apache Tomcat','Apache Traffic Server', 'apache tomcat']:\n",
    "        return 'Apache'\n",
    "    elif skill in ['Apache Hadoop','Hadoop']:\n",
    "        return 'Hadoop'\n",
    "    elif skill in ['Apache Kafka','Kafka','kafka']:\n",
    "        return 'Kafka'\n",
    "    elif skill in [ 'Apache Spark','Spark']:\n",
    "        return 'Spark'\n",
    "    elif skill in ['Apache ZooKeeper']:\n",
    "        return 'ZooKeeper'\n",
    "    elif skill in [ 'Azure','Azure Computer Vision','Azure Emotion','AZURE', 'Microsoft Azure']:\n",
    "        return 'Azure'\n",
    "    elif skill in ['C#']:\n",
    "        return 'C#'\n",
    "    elif skill in [ 'C', 'C / C++','C++','c','c++','Mfc','Mantis','Embedded C']:\n",
    "        return 'C / C++'\n",
    "    elif skill in ['AutoCAD','CAD']:\n",
    "        return 'CAD'\n",
    "    elif skill in [ 'CSS','CSS3','css 3','CSS 3','Tailwind CSS']:\n",
    "        return 'CSS'\n",
    "    elif skill in [ 'ElasticSearch','Elasticsearch', 'elasticsearch ','elasticsearch']:\n",
    "        return 'ElasticSearch'\n",
    "    elif skill in [ 'FPGA','FPGA 프로토 타이핑']:\n",
    "        return 'FPGA'\n",
    "    elif skill in ['Figma']:\n",
    "        return 'Figma'\n",
    "    elif skill in ['GCP','GCP(Google Cloud Platform)','GCPs','Google Cloud Platform']:\n",
    "        return 'GCP'\n",
    "    elif skill in ['GIS','GIS 시스템','GIS 응용 프로그램']:\n",
    "        return 'GIS'\n",
    "    elif skill in [ 'Git','GitHub','GitLab','Github','git','gitlab',\n",
    "                  'Gerrit Code Review','GitHub Actions','GitLab CI']:\n",
    "        return 'Git'\n",
    "    elif skill in ['Gradle']:\n",
    "        return 'Gradle'\n",
    "    elif skill in ['GraphQL']:\n",
    "        return 'GraphQL'\n",
    "    elif skill in ['HAProxy']:\n",
    "        return 'HAProxy'\n",
    "    elif skill in ['HLSL']:\n",
    "        return 'HLSL'\n",
    "    elif skill in [ 'HTML','HTML5','html5']:\n",
    "        return 'HTML'\n",
    "    elif skill in ['HTTP']:\n",
    "        return 'HTTP'\n",
    "    elif skill in [ 'JSP','JSP 개발', 'jsp']:\n",
    "        return 'JSP'\n",
    "    elif skill in ['Java', 'java']:\n",
    "        return 'Java'\n",
    "    elif skill in [ 'Node.js', 'NodeJS','Mongoose', 'node.js']:\n",
    "        return 'Node.js'\n",
    "    elif skill in [ 'NumPy','Numpy']:\n",
    "        return 'NumPy'\n",
    "    elif skill in ['ORCAD']:\n",
    "        return 'ORCAD'\n",
    "    elif skill in ['Pandas']:\n",
    "        return 'Pandas'\n",
    "    elif skill in ['Python','python']:\n",
    "        return 'Python'\n",
    "    elif skill in ['React',  'React.js','ReactJS','react']:\n",
    "        return 'React'\n",
    "    elif skill in [ 'Redux','Redux-Saga','Redux-Thunk','Redux.js','React.js Boilerplate', 'redux-saga']:\n",
    "        return 'Redux'\n",
    "    elif skill in ['Ruby']:\n",
    "        return 'Ruby'\n",
    "    elif skill in ['Ruby on Rails']:\n",
    "        return 'Ruby on Rails'\n",
    "    elif skill in [ 'SAP','SAP ERP','SAP FI','SAP FICO','SAP HR','SAP MM','SAP SD','SAP 구현']:\n",
    "        return 'SAP'\n",
    "    elif skill in [ 'Shell','Shell Script','Shell Scripting']:\n",
    "        return 'Shell'\n",
    "    elif skill in [  'Hibernate','JPA','JPA(Java Persistent API)', 'Spring', \n",
    "                   'Spring Batch','Spring Boot','Spring Cloud','Spring Framework',\n",
    "                  'spring','spring boot','spring framework', 'Spring MVC','Spring Data JPA']:\n",
    "        return 'Spring'\n",
    "    elif skill in [ 'Vue.JS','Vue.js','VueJS','vue.js']:\n",
    "        return 'Vue.JS'\n",
    "    elif skill in [ '.NET','.NET Core','.net']:\n",
    "        return '.NET'\n",
    "    elif skill in [ 'ASP', 'ASP .NET','ASP.NET']:\n",
    "        return 'ASP.NET'\n",
    "    elif skill in [ 'Linux', 'Linux kernel','CentOS', 'centos', 'linux','Embedded Linux']:\n",
    "        return 'Linux'\n",
    "    elif skill in ['UNIX','Unix']:\n",
    "        return 'UNIX'\n",
    "    elif skill in ['PyTorch','Pytorch', 'pytorch']:\n",
    "        return 'PyTorch'\n",
    "    elif skill in ['Flutter','flutter']:\n",
    "        return 'Flutter'\n",
    "    elif skill in ['Nest.js','NestJS']:\n",
    "        return 'Nest.js'\n",
    "    elif skill in ['Objective-C','ObjectiveC','objective-c']:\n",
    "        return 'Objective-C'\n",
    "    elif skill in ['JavaScript','javascript','ES6']:\n",
    "        return 'JavaScript'\n",
    "    elif skill in ['3Ds Max']:\n",
    "        return '3Ds Max'\n",
    "    elif skill in ['Sass(SCSS)', 'SCSS','Sass','SASS']:\n",
    "        return 'SASS'\n",
    "    elif skill in ['Rxswift', 'rxswift']:\n",
    "        return 'Rxswift'\n",
    "    elif skill in ['SQL 서버','Microsoft SQL Server']:\n",
    "        return 'SQL 서버'\n",
    "    elif skill in ['NoSQL', 'NoSql', 'nosql']:\n",
    "        return 'NoSQL'\n",
    "    elif skill in ['Sequelize.js','Sequelize']:\n",
    "        return 'Sequelize.js'\n",
    "    elif skill in ['Swift','SwiftUI', 'swift']:\n",
    "        return 'Swift'\n",
    "    elif skill in ['Tensorflow','Tensorflow Lite','TensorFlow', 'tensorflow']:\n",
    "        return 'Tensorflow'\n",
    "    elif skill in ['Django','django','DRF(Django REST framework)']:\n",
    "        return 'Django'\n",
    "    elif skill in ['jQuery', 'jquery ', 'jquery']:\n",
    "        return 'jQuery'\n",
    "    elif skill in ['Keras', 'keras']:\n",
    "        return 'Keras'\n",
    "    elif skill in ['Terraform']:\n",
    "        return 'Terraform'\n",
    "    elif skill in ['MariaDB','mariadb']:\n",
    "        return 'MariaDB'\n",
    "    elif skill in ['MATLAB','matlab']:\n",
    "        return 'MATLAB'\n",
    "    elif skill in ['MongoDB','mongodb']:\n",
    "        return 'MongoDB'\n",
    "    elif skill in ['MSSQL','mssql']:\n",
    "        return 'MSSQL'\n",
    "    elif skill in ['MySQL','mysql']:\n",
    "        return 'MySQL'\n",
    "    elif skill in ['Nginx','NGINX','nginx']:\n",
    "        return 'Nginx'\n",
    "    elif skill in ['Notion','notion.so']:\n",
    "        return 'Notion'\n",
    "    elif skill in ['OpenCV','opencv']:\n",
    "        return 'OpenCV'\n",
    "    elif skill in ['PHP','php']:\n",
    "        return 'PHP'\n",
    "    elif skill in ['PostgreSQL', 'postgresql']:\n",
    "        return 'PostgreSQL'\n",
    "    elif skill in ['R','r']:\n",
    "        return 'R'\n",
    "    elif skill in ['Redis','redis']:\n",
    "        return 'Redis'\n",
    "    elif skill in [ 'Unity','Unity3D','unity']:\n",
    "        return 'Unity'\n",
    "    elif skill in [ 'SQL', 'SQLite']:\n",
    "        return 'SQL'\n",
    "    elif skill in [ 'Go', 'Golang']:\n",
    "        return 'Go'\n",
    "    elif skill in ['CI/CD' ]:\n",
    "        return 'CI/CD' \n",
    "    elif skill in [ 'Docker' ]:\n",
    "        return  'Docker' \n",
    "    elif skill in ['ExpressJS']:\n",
    "        return 'ExpressJS'\n",
    "    elif skill in ['FastAPI' ]:\n",
    "        return 'FastAPI' \n",
    "    elif skill in ['Firebase']:\n",
    "        return 'Firebase'\n",
    "    elif skill in ['Flask' ]:\n",
    "        return 'Flask' \n",
    "    elif skill in ['JIRA' ,'Jira']:\n",
    "        return 'JIRA'\n",
    "    elif skill in ['Jenkins']:\n",
    "        return 'Jenkins' \n",
    "    elif skill in ['Kubernetes' ]:\n",
    "        return 'Kubernetes' \n",
    "    elif skill in ['Microservice Architecture' ]:\n",
    "        return 'Microservice Architecture' \n",
    "    elif skill in ['Next.js' ]:\n",
    "        return 'Next.js' \n",
    "    elif skill in ['OpenCL']:\n",
    "        return 'OpenCL' \n",
    "    elif skill in ['OpenGL']:\n",
    "        return 'OpenGL'\n",
    "    elif skill in ['Redmine' ]:\n",
    "        return 'Redmine' \n",
    "    elif skill in ['Rust' ]:\n",
    "        return 'Rust' \n",
    "    elif skill in ['SVN' ]:\n",
    "        return 'SVN' \n",
    "    elif skill in ['Selenium']:\n",
    "        return 'Selenium'\n",
    "    elif skill in ['TypeScript' ]:\n",
    "        return 'TypeScript' \n",
    "    elif skill in ['3D','3D 모델링','API 개발','Big Data', 'Blockchain', 'Data Analysis','Data Analysys','Database','Deep Learning', \n",
    "                   'DevOps','DirectX','EEO','ERP 소프트웨어', 'ETL', 'Eclipse','Embedded System', 'Excel','GPU','GUI', 'Google Analytics',\n",
    "                   'Google Apps', 'ISO','IT 관리','IT 운영','Image Processing','IntelliJ IDEA','IoT', 'JSON', 'ORM','OTN', 'PCB 디자인',\n",
    "                   'PCB 레이아웃 설계','PKI(Public key infrastructure)','PLC','PMP','QA 엔지니어링', 'RDBMS','REST','REST API',\n",
    "                   'RESTful Architecture', 'RESTful WebServices', 'RPC(Remote Procedure Call)', 'RTL 설계','RTL 코딩', 'React Admin',\n",
    "                   'Restful API', 'Rx',  'SCM', 'SDN','SEO', 'SNMP','SONET','SPI', 'SSH','SSO', 'Scrum', 'Slack', 'Slack API', 'SoC', \n",
    "                   'Storage', 'TCP','TCP/IP','TDD',  'UDP','UI 디자인', 'Verilog', 'WPF','WPF 개발','Web Socket', 'WebSocket',\n",
    "                   'WebSphere MQ', 'XML','XP', 'debugging','dlib',  'iOS','iOS 개발', '강의','개발','검증','고객 관계','고객 지원',\n",
    "                   '공공 부문','공차 분석','교육 관리','교육 기술','구매 관리', '기술 개발','기술 관리', '기술 교육', '기술 문서',\n",
    "                   '네비게이션 시스템', '네트워크 개발', '네트워크 관리','네트워크 보안', '네트워크 설계', '네트워크 운영',\n",
    "                   '네트워크 인프라', '데이터베이스', '딥 러닝', '라이브러리 관리', '로봇', '로봇 프로그래밍', '리눅스 커널',\n",
    "                   '마이크로프로세서','머신 비전', '모뎀', '모바일 기술', '모바일 장치', '백엔드 개발','보안', '보안 감사', '보안 관리',\n",
    "                   '복제', '빅 데이터', '샘플 관리', '샘플 준비','생산 계획', '서버', '서버 관리', '서버 아키텍처', '서비스 관리',\n",
    "                   '성능 측정', '소프트웨어 개발','솔루션 개발', '시스템 관리', '안드로이드 개발', '알고리즘 개발', '암호화', \n",
    "                   '연구 및 개발', '영상', '운영 관리', '운영체제', '웹 개발', '윈도우 모바일', '윈도우 프로그래밍', '유지보수', \n",
    "                   '인공 지능', '인프라','임베디드 소프트웨어', '임베디드 시스템', '자동차', '재고 관리', '전원 엔지니어링', \n",
    "                   '전자정부프레임워크', '정보 보안','정보 운영','정보관리','제안서 작성', '제어 시스템 설계', '제품 개발','차량',\n",
    "                   '최적화', '취약점 스캐닝','카메라', '컴파일러', '컴퓨터 비전', '클라우드 보안', '테스트 실행', '통신', '펌웨어', \n",
    "                   '품질 관리', '프로그램 관리', '프로젝트 관리', '프론트엔드 개발자', '하드웨어', '회로', '회로 분석', '회로 설계',\n",
    "                   'Agile','Children','Windows','Windows 8','Windows Embedded','Windows Server','Windows kernel', 'Windows 서버',\n",
    "                   'BigData', 'DB', 'Etl','ai/인공지능','blockchain','ios','windows','3D Rendering','3D Volume Rendering','AI/인공지능',\n",
    "                   'Cisco','DeepLearning','ERP','Embedded','HW','ISMS','MCU,''MQTT','MachineLearning','Matplotlib','Network','Optimize',\n",
    "                   'Pads','PyCharm','QA','RDB','Red Hat Enterprise ','SW','Switch','switch','Smartcontract','VPN','VR','cisco','WebStorm',\n",
    "                   'deeplearning','embedded','machinelearning', 'network', 'l2', 'l3','l4','rest api','sw','hw','WordPress', 'ADC', 'AJAX',\n",
    "                   'API','AR', 'ARM', 'Adobe XD', 'Ajax', 'Appium', 'Aurora DB','Axios', 'Babel', 'Bash', 'BitBucket', 'Bootstrap', 'CAM',\n",
    "                   'CRM','CUDA','CodeIgniter','Confluence','Consul','Coroutine', 'Cucumber', 'DACS', 'DART for Publishers', \n",
    "                   'DBA(Database administration)','DWDM', 'Dart','Delphi', 'Element UI', 'EnCase','Entity Framework', 'Ethereum','FFmpeg',\n",
    "                   'FMEA','Flow','GStreamer','Hyperledger', 'I2C', 'IDA(Interactive DisAssembler)', 'IIS','IP', 'IPS','JSTL', 'JsonAPI', \n",
    "                   'Klaytn', 'Laravel', 'LiDAR', 'Lua', 'MES', 'MFC', 'ML', 'MVC', 'MVVM', 'MXNET', 'Machine Learning', 'Machine Vision', \n",
    "                   'Material-UI', 'Maven', 'Memcached', 'Moodle', 'MyBatis', 'NFC', 'NLP', 'NVIDIA TensorRT', 'Netty','OOP','OpenFlow',\n",
    "                   'OpenMP', 'OpenStack','Oracle', 'Oracle Database', 'Perl', 'PowerBuilder', 'Prisma', 'Qt','RHEL', 'ROS','RS232', 'RTOS',\n",
    "                   'RabbitMQ', 'STL', 'STP',  'SVG','Scala', 'Scikit-Learn', 'scikit-learn', 'Servlets', 'Shader', 'Simulink', 'Sketch', 'Socket.IO', \n",
    "                   'Solidity', 'Spa',  'Spinnaker', 'Storybook',  'Sybase',  'SLAM', 'TCL', 'Tableau','TeamCity', 'Tomcat', 'Truffle',\n",
    "                   'TypeORM','UML', 'Ubuntu', 'Unreal Engine', 'VM웨어', 'Visual Basic', 'Visual Studio', 'Visual Studio Code','Vuetify.js',\n",
    "                   'Web3.py','web3.js', 'WebGL', 'WebRTC', 'Webpack', 'WinForm', 'Xcode', 'Xilinx', 'Yarn', 'gRPC', 'DevExpress',\n",
    "                   '고객 중심', 'Windows 서비스', 'EMC 규정 준수', '의료 장비', 'UX 디자인', '의료 영상', '비즈니스 분석', '설계', '보안 운영', '의료 기기'  ]:\n",
    "        return None\n",
    "    else:\n",
    "        return skill"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로그래머스 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=114.0.5735.110)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x0085A813+48355]\n\t(No symbol) [0x007EC4B1]\n\t(No symbol) [0x006F5358]\n\t(No symbol) [0x006DD293]\n\t(No symbol) [0x0073E37B]\n\t(No symbol) [0x0074C473]\n\t(No symbol) [0x0073A536]\n\t(No symbol) [0x007182DC]\n\t(No symbol) [0x007193DD]\n\tGetHandleVerifier [0x00ABAABD+2539405]\n\tGetHandleVerifier [0x00AFA78F+2800735]\n\tGetHandleVerifier [0x00AF456C+2775612]\n\tGetHandleVerifier [0x008E51E0+616112]\n\t(No symbol) [0x007F5F8C]\n\t(No symbol) [0x007F2328]\n\t(No symbol) [0x007F240B]\n\t(No symbol) [0x007E4FF7]\n\tBaseThreadInitThunk [0x758500C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77797B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77797B1E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m buttons\u001b[39m.\u001b[39mclick()\n\u001b[0;32m      9\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m3\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m html \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39;49mpage_source\n\u001b[0;32m     12\u001b[0m \u001b[39m# 직무 딕셔너리 받아내기\u001b[39;00m\n\u001b[0;32m     13\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(html, \u001b[39m'\u001b[39m\u001b[39mlxml\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:541\u001b[0m, in \u001b[0;36mWebDriver.page_source\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    533\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpage_source\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    534\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Gets the source of the current page.\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \n\u001b[0;32m    536\u001b[0m \u001b[39m    :Usage:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m            driver.page_source\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 541\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET_PAGE_SOURCE)[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[0;32m    441\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Playdata\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=114.0.5735.110)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x0085A813+48355]\n\t(No symbol) [0x007EC4B1]\n\t(No symbol) [0x006F5358]\n\t(No symbol) [0x006DD293]\n\t(No symbol) [0x0073E37B]\n\t(No symbol) [0x0074C473]\n\t(No symbol) [0x0073A536]\n\t(No symbol) [0x007182DC]\n\t(No symbol) [0x007193DD]\n\tGetHandleVerifier [0x00ABAABD+2539405]\n\tGetHandleVerifier [0x00AFA78F+2800735]\n\tGetHandleVerifier [0x00AF456C+2775612]\n\tGetHandleVerifier [0x008E51E0+616112]\n\t(No symbol) [0x007F5F8C]\n\t(No symbol) [0x007F2328]\n\t(No symbol) [0x007F240B]\n\t(No symbol) [0x007E4FF7]\n\tBaseThreadInitThunk [0x758500C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77797B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77797B1E+238]\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://career.programmers.co.kr/job?page=1&min_career=0&order=recent')\n",
    "time.sleep(3)  # 3초 동안 대기\n",
    "\n",
    "# 직무 버튼 누르기\n",
    "buttons = driver.find_element(By.XPATH, '//*[@id=\"search-form\"]/div[2]/div[1]/button')\n",
    "buttons.click()\n",
    "\n",
    "time.sleep(3)\n",
    "html = driver.page_source\n",
    "\n",
    "# 직무 딕셔너리 받아내기\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "labels=soup.find_all('label', class_=\"job_category_label\")\n",
    "position_url = {}\n",
    "for label in labels:\n",
    "    position = classify_position(label.get_text(strip=True))\n",
    "    if position is not None:\n",
    "        url= \"&job_category_ids=\" + label.input['value']\n",
    "        if position in position_url:\n",
    "            position_url[position] = position_url[position] + url\n",
    "        else:\n",
    "            position_url[position] = url\n",
    "            \n",
    "print(\"position_url 딕셔너리를 완성했습니다!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 시작\n",
    "for position, url in position_url.items():\n",
    "    print(f\"{position} 공고 탐방을 시작하겠습니다!\")\n",
    "    URL=f'https://career.programmers.co.kr/job?page=1&min_career=0&order=recent{url}'\n",
    "    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "    driver.get(URL)\n",
    "\n",
    "    time.sleep(4)  # 3초 동안 대기\n",
    "    driver.implicitly_wait(10)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # 각 직무의 마지막 페이지 알아보기\n",
    "    last_page=soup.find_all(\"span\",class_=\"page-link\")\n",
    "    last_page=int(last_page[-2].get_text(strip=True))\n",
    "    print(f\"{position}의 마지막 페이지는 {last_page}!\")\n",
    "    \n",
    "    url_num=[]\n",
    "    \n",
    "    # 각 직군의 전체 공고 url받아내기\n",
    "    for page in range(1, last_page + 1):\n",
    "        orig_url = f'https://career.programmers.co.kr/job?page={page}&min_career=0&order=recent{url}'\n",
    "        driver.get(orig_url)\n",
    "        imgcount = driver.find_elements(By.CSS_SELECTOR, '.list-positions')\n",
    "\n",
    "        for i in imgcount:\n",
    "            s = i.get_attribute('outerHTML')\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        divs = soup.find_all('ul', class_='list-positions')\n",
    "\n",
    "        for div in divs:\n",
    "            lists = div.find_all('li', class_='list-position-item')\n",
    "            for list in lists:\n",
    "                atag = list.find('a', class_='position-link')\n",
    "                url_num.append(atag.attrs['href'].split('/')[-1])\n",
    "\n",
    "        print(f\"{position} 공고 {page}/{last_page}\")\n",
    "        \n",
    "        n = 0\n",
    "        \n",
    "    print(f\"{position}의 총 공고수는  {len(url_num)}개!\")\n",
    "    \n",
    "    for url in url_num:\n",
    "        URL = f'https://programmers.co.kr/job_positions/{url}'\n",
    "\n",
    "        if URL in link_set:\n",
    "            # 이미 존재하는 URL일 경우\n",
    "            present_set.add(URL)\n",
    "            print(f\"아직 있는 공고입니다. URL: {URL}\")\n",
    "        else:\n",
    "            headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "            driver.get(url=URL)\n",
    "\n",
    "            time.sleep(4)  # 3초 동안 대기\n",
    "\n",
    "            driver.implicitly_wait(10)\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "            # 공고명\n",
    "            title_element = soup.select_one(\"h2\")\n",
    "            title = title_element.text if title_element else None\n",
    "\n",
    "            # 회사명\n",
    "            company = soup.select_one('h4.e_ow99Z6WyqEsY3oG3gk a').text\n",
    "\n",
    "            # 지원 마감\n",
    "            deadline = soup.find(\"div\", text=\"지원 마감\")\n",
    "            deadline = deadline.find_next_sibling(\"div\").text if deadline and deadline.find_next_sibling(\"div\") else None\n",
    "\n",
    "            # 근무 위치 정보 추출\n",
    "            work_location = soup.find(\"div\", text=\"근무 위치\")\n",
    "            work_location = work_location.find_next_sibling(\"div\").text if work_location and work_location.find_next_sibling(\"div\") else None\n",
    "\n",
    "            # 기술 스택 정보 추출\n",
    "            stacks = soup.find(\"ul\", class_=\"cV112CI8tyAk3_QcrdKs\")\n",
    "            stack = []\n",
    "\n",
    "            if stacks:\n",
    "                for li_tag in stacks.find_all('li'):\n",
    "                    skill = li_tag.text\n",
    "                    classified_skill = classify_skill(skill)\n",
    "\n",
    "                    if classified_skill is None:\n",
    "                        pass\n",
    "                    else:\n",
    "                        if classified_skill not in stack:\n",
    "                            stack.append(classified_skill)\n",
    "            else:\n",
    "                stack = None\n",
    "\n",
    "            # 추출한 정보를 데이터프레임에 추가\n",
    "            new_df.loc[len(new_df)] = [title, company, position, deadline, work_location, stack, URL]\n",
    "            print(f\"현재까지 모인 {position} 공고:{n+1}개!\")\n",
    "\n",
    "        n += 1\n",
    "\n",
    "    print(f\"{position} 공고 전체 끝!\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원티드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "# 페이지 열기\n",
    "driver.get('https://www.wanted.co.kr/wdlist/518?country=kr&job_sort=company.response_rate_order&years=0&locations=all')\n",
    "time.sleep(3)  # 3초 동안 대기\n",
    "    \n",
    "# 직무 버튼 누르기\n",
    "buttons = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div[3]/article/div/div[2]/button/span[2]')\n",
    "buttons.click()\n",
    "\n",
    "time.sleep(3)\n",
    "html = driver.page_source\n",
    "\n",
    "# 직무 리스트 받아내기\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "positions=soup.find_all('button', class_=\"JobCategoryItem_JobCategoryItem__oUaZr\")\n",
    "positions = [position.text for position in positions][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_position=set()\n",
    "\n",
    "# 지역 저장 시 사용하는 keywords\n",
    "keywords = ['대한민국', '서울', '경기', '제주', '울산', '경상북도', '경북', '부산', '인천', '대전', '경기']\n",
    "\n",
    "for i in range(0,len(positions)):\n",
    "    position = classify_position(positions[i])\n",
    "    print(f\"지금 포지션은 {position}\")\n",
    "    if position is not None:\n",
    "        if i==0:\n",
    "            pass\n",
    "        else:\n",
    "            driver.close()\n",
    "            driver = webdriver.Chrome()\n",
    "\n",
    "            # 페이지 열기\n",
    "            driver.get('https://www.wanted.co.kr/wdlist/518/873?country=kr&job_sort=company.response_rate_order&years=0&locations=all')\n",
    "\n",
    "            buttons = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div[3]/article/div/div[2]/button')\n",
    "            buttons.click()\n",
    "\n",
    "            driver.implicitly_wait(10)\n",
    "\n",
    "            button = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div[3]/article/div/div[2]/section/div[1]/div/button[2]')\n",
    "            button.click()\n",
    "\n",
    "            button = driver.find_element(By.XPATH, f'//*[@id=\"__next\"]/div[3]/article/div/div[2]/section/div[1]/div/button[{i+2}]')\n",
    "            button.click()\n",
    "\n",
    "            button = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/div[3]/article/div/div[2]/section/div[2]/button/span[2]')\n",
    "            button.click()\n",
    "        print(f'{i+1}. 지금부터 {position} 시작!')\n",
    "\n",
    "        # position 별 크롤링 하는 것\n",
    "\n",
    "        # 스크롤 하는 횟수 세는 변수\n",
    "        scroll_count = 0\n",
    "\n",
    "        # 스크롤 내리기\n",
    "        while True:\n",
    "            # 스크롤 위치 저장\n",
    "            last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "\n",
    "            # 스크롤 내리기\n",
    "            driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "\n",
    "            # 로딩 대기\n",
    "            time.sleep(3)\n",
    "\n",
    "            # 스크롤 위치 갱신\n",
    "            new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "            scroll_count += 1\n",
    "\n",
    "            # 스크롤을 더 이상 내릴 수 없는 경우 종료\n",
    "            if new_height == last_height or scroll_count == 10000:\n",
    "                break\n",
    "\n",
    "\n",
    "        # 페이지 내용 가져오기\n",
    "        page_source = driver.page_source\n",
    "\n",
    "        # BeautifulSoup을 사용하여 데이터 추출\n",
    "        soup = BeautifulSoup(page_source, 'lxml')\n",
    "        # 원하는 정보를 찾기 위해 적절한 BeautifulSoup 메소드를 사용합니다.\n",
    "\n",
    "        a=soup.find(\"div\", class_=\"List_List_container__JnQMS\")\n",
    "        href_selector = 'div.Card_className__u5rsb a[href]'\n",
    "        href_values = [a['href'] for a in soup.select(href_selector)]\n",
    "\n",
    "        # 결과 출력\n",
    "        url_num=[href for href in href_values]\n",
    "        print(f'{position} url주소 추출 끝!')\n",
    "\n",
    "        print(\"이제 데이터 프레임 채워넣기를 시작하겠습니다.\")\n",
    "\n",
    "        # 데이터프레임 채워넣기 시작\n",
    "        n=1\n",
    "        for url in url_num:\n",
    "            URL = f'https://www.wanted.co.kr//{url}'\n",
    "            \n",
    "            if URL in link_set:\n",
    "                # 이미 존재하는 URL일 경우\n",
    "                present_set.add(URL)\n",
    "                print(f\"아직 있는 공고입니다. URL: {URL}\")\n",
    "            else:\n",
    "                \n",
    "                if URL in new_df['링크'].values:\n",
    "                    if position not in done_position:\n",
    "                    # 이미 존재하는 URL인 경우 해당 position 값에 추가\n",
    "                        existing_positions = new_df.loc[new_df['링크'] == URL, '직무']\n",
    "                        updated_position = existing_positions + \", \" + position\n",
    "                        new_df.loc[new_df['링크'] == URL, '직무'] = updated_position\n",
    "                        print(\"기존에 있는 공고이기에 position만 추가했습니다.\")\n",
    "                else:\n",
    "                    headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "                    # 웹 페이지 가져오기\n",
    "                    response = requests.get(URL)\n",
    "                    html_content = response.content\n",
    "\n",
    "                    # BeautifulSoup 객체 생성\n",
    "                    soup = BeautifulSoup(html_content, 'lxml')\n",
    "                    script_content = soup.select(\"script\", type='application/ld+json')[0]\n",
    "                    data = json.loads(script_content.string)\n",
    "\n",
    "                    # 공고명\n",
    "                    title=data['title']\n",
    "                    #회사명\n",
    "                    company=data['hiringOrganization']['name']\n",
    "                    #마감일\n",
    "                    deadline=data['validThrough']\n",
    "                    #근무지\n",
    "                    address=data['jobLocation']['address']['streetAddress']\n",
    "\n",
    "                    if address == '':\n",
    "                        work_location = None\n",
    "\n",
    "                    else: \n",
    "                        first_word = address.split()[0]\n",
    "                        if any(keyword in first_word for keyword in keywords):\n",
    "                            work_location = address\n",
    "                        else:\n",
    "                            region = data['jobLocation']['address']['addressRegion']\n",
    "                            work_location = f\"{region[:2]} {address}\"\n",
    "\n",
    "                    driver = webdriver.Chrome()\n",
    "                    driver.get(url=URL)\n",
    "\n",
    "                    html = driver.page_source\n",
    "                    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "                    # 기술 스택\n",
    "                    stack_elements = soup.find_all(\"div\", class_=\"SkillItem_SkillItem__E2WtM\")\n",
    "                    stack = []\n",
    "\n",
    "                    for element in stack_elements:\n",
    "                        skill = element.text\n",
    "                        classified_skill = classify_skill(skill)\n",
    "\n",
    "                        if classified_skill is None:\n",
    "                            pass\n",
    "                        else:\n",
    "                            if classified_skill not in stack:\n",
    "                                stack.append(classified_skill)\n",
    "\n",
    "\n",
    "                    #추출한 정보를 데이터프레임에 추가\n",
    "                    new_df.loc[len(new_df)] = [title, company, position, deadline, work_location, stack, URL]\n",
    "                    print(f\"{position}의 {n}번째 공고 정보 끝!\")\n",
    "                    n+=1\n",
    "\n",
    "        print(f\"{position} 데이터 프레임 생성 끝!\")\n",
    "        done_position.add(position)\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 점핏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "service = Service(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "orig_url = 'https://www.jumpit.co.kr/positions' # 크롤링 할 사이트\n",
    "\n",
    "driver.get(orig_url)\n",
    "time.sleep(2)\n",
    "\n",
    "#스크롤 전 높이\n",
    "before_h = driver.execute_script(\"return window.scrollY\")  # 스크롤을 하지 않았으니 0이 변수에 대입\n",
    "\n",
    "career = driver.find_element(By.XPATH, '/html/body/div[1]/main/div/div[1]/div/div[1]/div/div[1]/div[2]/button')\n",
    "career.click()\n",
    "time.sleep(2)\n",
    "\n",
    "rookie = driver.find_element(By.XPATH, '//*[@id=\"root\"]/main/div/div/div/div[1]/div/div[1]/div[2]/div[1]/div[2]/div/div/div[2]/label')\n",
    "rookie.click()\n",
    "time.sleep(2)\n",
    "\n",
    "first_click = driver.find_element(By.XPATH, '//*[@id=\"root\"]/main/div/div/div/div[1]/div/div[1]/div[2]/button')\n",
    "first_click.click()\n",
    "time.sleep(1)\n",
    "\n",
    "add_list = []\n",
    "pos = ['백엔드', '프론트엔드', '웹개발', '모바일', '모바일', '백엔드', '데이터 엔지니어', 'AI/ML', 'DevOps',]\n",
    "pos_num = [2, 3, 4, 5, 6, 10, 11, 12, 13]\n",
    "pos_dict = dict(zip(pos_num, pos))  # 딕셔너리 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pos_num:\n",
    "    position = driver.find_element(By.XPATH, f'//*[@id=\"root\"]/main/div/section/section/div[1]/button[{i}]')\n",
    "    position_text = pos_dict[i]\n",
    "    position.click()\n",
    "\n",
    "    # 무한 스크롤\n",
    "    prev_page_source = \"\"\n",
    "    while True:\n",
    "        # 맨 아래로 스크롤\n",
    "        driver.find_element(By.CSS_SELECTOR, \"body\").send_keys(Keys.END)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # 페이지 소스 가져오기\n",
    "        current_page_source = driver.page_source\n",
    "\n",
    "        if current_page_source == prev_page_source:\n",
    "            # 이전 페이지 소스와 현재 페이지 소스가 같으면 스크롤이 끝까지 이동한 것으로 판단하여 반복문을 탈출\n",
    "            break\n",
    "\n",
    "        prev_page_source = current_page_source\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    items = soup.select('div.sc-fIosxK.fKzIXW')\n",
    "\n",
    "    for item in items:\n",
    "        add_elem = item.select('a')\n",
    "        for add in add_elem:\n",
    "            add_list.append(('https://www.jumpit.co.kr' + add['href'], position_text))\n",
    "\n",
    "    driver.find_element(By.CSS_SELECTOR, \"body\").send_keys(Keys.HOME)\n",
    "    time.sleep(1)\n",
    "    position.click()\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for orig_url, position in add_list:\n",
    "    if orig_url in link_set:\n",
    "        # 이미 존재하는 URL일 경우\n",
    "        present_set.add(orig_url)\n",
    "        print(f\"아직 있는 공고입니다. URL: {orig_url}\")\n",
    "    else:\n",
    "        driver.get(orig_url)\n",
    "        time.sleep(4)\n",
    "        title = driver.find_element(By.CSS_SELECTOR, 'section.sc-gnnDb > h1').text\n",
    "        company = driver.find_element(By.CSS_SELECTOR, 'div.position_title_box_desc > a').text\n",
    "\n",
    "        try:\n",
    "            deadline_text = driver.find_element(By.CSS_SELECTOR, 'dl.sc-itWPBs:nth-child(4) > dd').text\n",
    "            if re.match(r\"\\d{4}-\\d{2}-\\d{2}\", deadline_text):\n",
    "                deadline = deadline_text  # 날짜 형식이라면 해당 값을 그대로 사용\n",
    "            else:\n",
    "                deadline = \"상시 채용\"\n",
    "        except NoSuchElementException:\n",
    "                deadline = \"상시 채용\"\n",
    "\n",
    "        try:    \n",
    "            element = driver.find_element(By.XPATH, '//*[@id=\"root\"]/main/div/div[2]/div/section[3]/dl[4]/dd/ul/li')\n",
    "            work_location = element.text.replace('지도보기', '').replace('주소복사', '').replace('\\.', '')\n",
    "        except NoSuchElementException:\n",
    "            work_location = None\n",
    "        try:\n",
    "                skill_elements = driver.find_elements(By.XPATH, '/html/body/div[1]/main/div/div[2]/div/section[2]/dl[1]/dd/pre/div')\n",
    "                stack = []\n",
    "\n",
    "                for element in skill_elements:\n",
    "                    skill = element.text\n",
    "                    classified_skill = classify_skill(skill)\n",
    "\n",
    "                    if classified_skill is None:\n",
    "                        pass\n",
    "                    else:\n",
    "                        if classified_skill not in stack:\n",
    "                            stack.append(classified_skill)\n",
    "\n",
    "            \n",
    "        except NoSuchElementException:\n",
    "            stack = []\n",
    "        link = orig_url\n",
    "    \n",
    "        new_df.loc[len(new_df)] = [title, company, position, deadline, work_location, stack, URL]\n",
    "        print(f\"{position}의 {n}번째 공고 정보 끝!\")\n",
    "        \n",
    "driver.quit()    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 삭제해야 하는 데이터프레임 json 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complement = link_set - present_set\n",
    "delete_df = now_df[now_df['링크'].isin(complement)]\n",
    "# 배경화면에 저장\n",
    "delete_df.to_json(r\"C:\\Users\\Playdata\\Desktop\\delete_df.json\", orient=\"records\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새롭게 들어가는 데이터프레임"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 공고에 모두 있는 회사명 데이터 빼내기 filtered_df\n",
    "def preprocess_and_compare_links(df,intersection):\n",
    "    # 공통으로 있는 회사만 필터링\n",
    "    filtered_df = df[df['회사명'].isin(intersection)]\n",
    "    # NaN인 기술스택을 '[]'로 대체\n",
    "    filtered_df.loc[filtered_df['기술스택'].apply(lambda x: isinstance(x, float)), '기술스택'] = filtered_df.loc[filtered_df['기술스택'].apply(lambda x: isinstance(x, float)), '기술스택'].apply(lambda x: '[]' if pd.isnull(x) else x)\n",
    "    # 공고명에서 '신입'과 ()로 둘러싸인 부분 삭제\n",
    "    filtered_df['공고명'] = filtered_df['공고명'].apply(lambda x: re.sub(r' \\(신입.*?\\)|신입|\\[신입.*?\\] |\\[코스닥상장사\\] |채용', '', x))\n",
    "    filtered_df['공고명'] = filtered_df['공고명'].apply(lambda x: re.sub(r'\\(신입/경력\\)', '', x))\n",
    "\n",
    "    # 중복되지 않은 데이터를 추출\n",
    "    df = df[~df['링크'].isin(filtered_df['링크'])]\n",
    "    \n",
    "    return df,filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회사가 같고, 링크는 다르고, 한 공고문이 다른 공고문을 완전히 포함하고 있을 때 \n",
    "# 중복된 공고명을 가진 그룹 찾기\n",
    "grouped = filtered_df.groupby('회사명')\n",
    "def find_exact_matches(grouped, url_a, url_b):\n",
    "    exact_match_df = pd.DataFrame(columns=grouped.first().columns)\n",
    "    for _, group in grouped:\n",
    "        if len(group) > 1:\n",
    "            for i in range(len(group)):\n",
    "                a_group = group.iloc[i]\n",
    "                for j in range(i + 1, len(group)):\n",
    "                    b_group = group.iloc[j]\n",
    "                    if ((a_group['링크'].startswith(url_a) and b_group['링크'].startswith(url_b))\n",
    "                        or (a_group['링크'].startswith(url_b) and b_group['링크'].startswith(url_a))):\n",
    "                        if a_group['공고명'].replace(\" \", \"\") == b_group['공고명'].replace(\" \", \"\"):\n",
    "                            if a_group['기술스택'] != b_group['기술스택']:\n",
    "                                combined_tech_stack = set()\n",
    "\n",
    "                                if isinstance(a_group['기술스택'], str):\n",
    "                                    a_group['기술스택'] = ast.literal_eval(a_group['기술스택'])\n",
    "                                    for a_stack in a_group['기술스택']:\n",
    "                                        combined_tech_stack.add(a_stack)\n",
    "\n",
    "                                if isinstance(b_group['기술스택'], str):\n",
    "                                    b_group['기술스택'] = ast.literal_eval(b_group['기술스택'])\n",
    "                                    for b_stack in b_group['기술스택']:\n",
    "                                        combined_tech_stack.add(b_stack)\n",
    "                                    \n",
    "                                combined_tech_stack = list(combined_tech_stack) \n",
    "\n",
    "                                a_group['기술스택'] = combined_tech_stack\n",
    "                                b_group['기술스택'] = combined_tech_stack\n",
    "\n",
    "                            exact_match_df = exact_match_df.append(a_group)\n",
    "                            exact_match_df = exact_match_df.append(b_group)\n",
    "\n",
    "    return exact_match_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포함관계인 공고문 찾기\n",
    "def find_included_matches(grouped, url_a, url_b):\n",
    "    included_df = pd.DataFrame(columns=grouped.first().columns)\n",
    "    for _, group in grouped:\n",
    "        if len(group) > 1:\n",
    "            for i in range(len(group)):\n",
    "                a_group = group.iloc[i]\n",
    "                for j in range(i + 1, len(group)):\n",
    "                    b_group = group.iloc[j]\n",
    "                    if ((a_group['링크'].startswith(url_a) and b_group['링크'].startswith(url_b))\n",
    "                        or (a_group['링크'].startswith(url_b) and b_group['링크'].startswith(url_a))):\n",
    "                        if (a_group['공고명'].replace(\" \", \"\") in b_group['공고명'].replace(\" \", \"\") \n",
    "                        or b_group['공고명'].replace(\" \", \"\") in a_group['공고명'].replace(\" \", \"\")):\n",
    "                            if a_group['기술스택'] != b_group['기술스택']:\n",
    "                                combined_tech_stack = set()\n",
    "\n",
    "                                if isinstance(a_group['기술스택'], str):\n",
    "                                    a_group['기술스택'] = ast.literal_eval(a_group['기술스택'])\n",
    "                                    for a_stack in a_group['기술스택']:\n",
    "                                        combined_tech_stack.add(a_stack)\n",
    "\n",
    "                                if isinstance(b_group['기술스택'], str):\n",
    "                                    b_group['기술스택'] = ast.literal_eval(b_group['기술스택'])\n",
    "                                    for b_stack in b_group['기술스택']:\n",
    "                                        combined_tech_stack.add(b_stack)\n",
    "\n",
    "                                combined_tech_stack = list(combined_tech_stack) \n",
    "\n",
    "                                a_group['기술스택'] = combined_tech_stack\n",
    "                                b_group['기술스택'] = combined_tech_stack\n",
    "\n",
    "                            included_df = included_df.append(a_group)\n",
    "                            included_df = included_df.append(b_group)\n",
    "    return included_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(filtered_df, exact_match_df, included_df, link_start):\n",
    "    solo_df = filtered_df[~filtered_df['링크'].isin(exact_match_df['링크'])]\n",
    "    solo_df = solo_df[~solo_df['링크'].isin(included_df['링크'])]\n",
    "\n",
    "    exact_match_df['기술스택'] = exact_match_df['기술스택'].apply(lambda x: str(x))\n",
    "    included_df['기술스택'] = included_df['기술스택'].apply(lambda x: str(x))\n",
    "\n",
    "    duplicates_df = pd.merge(exact_match_df, included_df, how='outer')\n",
    "\n",
    "    duplicates_df = duplicates_df[duplicates_df['링크'].str.startswith(link_start)]\n",
    "\n",
    "    # solo_df를 더함\n",
    "    final_df = df.append(solo_df, ignore_index=True)  # 이 부분을 수정했습니다.\n",
    "\n",
    "    # duplicates_df를 더함\n",
    "    final_df = final_df.append(duplicates_df, ignore_index=True)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 데이터끼리 같은 공고 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = new_df[new_df['링크'].str.startswith('https://programmers.co.kr/')]\n",
    "df2 = new_df[new_df['링크'].str.startswith('https://www.wanted.co.kr/')]\n",
    "df3 = new_df[new_df['링크'].str.startswith('https://jumpit.co.kr')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(df1) !=0) and (len(df2) !=0):\n",
    "    intersection = pd.Series(list(set(df1['회사명'].unique()) & set(df2['회사명'].unique())))\n",
    "    if len(intersection) !=0:\n",
    "        new_df, filtered_df = preprocess_and_compare_links(new_df, intersection)\n",
    "        grouped = filtered_df.groupby('회사명')\n",
    "        \n",
    "        exact_match_df = find_exact_matches(grouped, 'https://programmers.co.kr', 'https://www.wanted.co.kr')\n",
    "        \n",
    "        included_df = find_included_matches(grouped, 'https://programmers.co.kr', 'https://www.wanted.co.kr')\n",
    "        \n",
    "        new_df = process_df(filtered_df, exact_match_df, included_df, 'https://programmers.co.kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(df1) != 0) and (len(df3) != 0):\n",
    "    new_df['근무지'] = new_df['근무지'].str.replace('\\n·', '')\n",
    "    intersection = pd.Series(list(set(df['회사명'].unique()) & set(df3['회사명'].unique())))\n",
    "    if len(intersection) !=0:\n",
    "        new_df,filtered_df=preprocess_and_compare_links(new_df,intersection)\n",
    "        # 회사가 같고, 링크는 다르고, 한 공고문이 다른 공고문을 완전히 포함하고 있을 때 \n",
    "        # 중복된 공고명을 가진 그룹 찾기\n",
    "        grouped = filtered_df.groupby('회사명')\n",
    "\n",
    "        # 완전히 일치하는 경우를 찾는 코드\n",
    "        exact_match_df = pd.DataFrame(columns=filtered_df.columns)\n",
    "        exact_match_df = exact_match_df.append(find_exact_matches(grouped, 'https://programmers.co.kr', 'https://www.jumpit.co.kr'))\n",
    "\n",
    "        # 포함관계인 경우를 찾는 코드\n",
    "        included_df = pd.DataFrame(columns=filtered_df.columns)\n",
    "        included_df = included_df.append(find_included_matches(grouped, 'https://programmers.co.kr', 'https://www.jumpit.co.kr'))\n",
    "\n",
    "        new_df = process_df(filtered_df, exact_match_df, included_df, 'https://www.jumpit.co.kr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(df2) != 0) and (len(df3) != 0):\n",
    "    new_df['근무지'] = new_df['근무지'].str.replace('\\n·', '')\n",
    "    intersection = pd.Series(list(set(df['회사명'].unique()) & set(df3['회사명'].unique())))\n",
    "    if len(intersection) !=0:\n",
    "        new_df,filtered_df=preprocess_and_compare_links(new_df,intersection)\n",
    "        # 회사가 같고, 링크는 다르고, 한 공고문이 다른 공고문을 완전히 포함하고 있을 때 \n",
    "        # 중복된 공고명을 가진 그룹 찾기\n",
    "        grouped = filtered_df.groupby('회사명')\n",
    "​\n",
    "        # 완전히 일치하는 경우를 찾는 코드\n",
    "        exact_match_df = pd.DataFrame(columns=filtered_df.columns)\n",
    "        exact_match_df = exact_match_df.append(find_exact_matches(grouped, 'https://www.wanted.co.kr', 'https://www.jumpit.co.kr'))\n",
    "​\n",
    "        # 포함관계인 경우를 찾는 코드\n",
    "        included_df = pd.DataFrame(columns=filtered_df.columns)\n",
    "        included_df = included_df.append(find_included_matches(grouped, 'https://www.wanted.co.kr', 'https://www.jumpit.co.kr'))\n",
    "​\n",
    "        new_df = process_df(filtered_df, exact_match_df, included_df, 'https://www.jumpit.co.kr')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new_df 전처리"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 직무 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['직무'] = new_df['직무'].str.split(', ')\n",
    "# 웹개발 혼자 있을 때\n",
    "new_df['직무'] = new_df['직무'].apply(lambda x: [\"프론트엔드\", \"백엔드\"] if str(x) == str([\"웹개발\"]) else x)\n",
    "# 웹개발이 다른 직무와 같이 있을 때\n",
    "new_df['직무'] = new_df['직무'].apply(lambda x: [item for item in x if item != '웹개발'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(r'C:\\Users\\Playdata\\Desktop\\df_pos.csv', index=False, encoding='cp949')\n",
    "new_df=pd.read_csv(r'C:\\Users\\Playdata\\Desktop\\df_pos.csv', encoding='cp949')\n",
    "\n",
    "new_df['직무'] = new_df['직무'].str.replace(\"'\", '\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기술스택 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기술 스택 획일화\n",
    "# np.where(condition, x, y)를 활용해서 condition이 참일 경우 x를, 아닌 경우 y로!\n",
    "new_df['기술스택'] = new_df['기술스택'].str.replace(\"'\", '\"')\n",
    "new_df['기술스택'] = np.where((new_df['기술스택'].isnull()) | (new_df['기술스택'] == \"[]\"), \"\"\"[\"\"]\"\"\", new_df['기술스택'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마감일 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['마감일'] = new_df['마감일'].str.replace('상시', '상시 채용')\n",
    "new_df['마감일'] = new_df['마감일'].str.replace('채용 채용', '채용')\n",
    "new_df['마감일'] = new_df['마감일'].fillna('상시 채용')\n",
    "\n",
    "# 날짜 형식 2023-04-12\n",
    "def format_date(date_str):\n",
    "    if date_str.startswith('상시 채용'):\n",
    "        return date_str\n",
    "#     elif date_str.startswith('상시'):\n",
    "#         return date_str\n",
    "    elif ':' in date_str:\n",
    "        date_obj = datetime.datetime.strptime(date_str, '%y년 %m월 %d일 %H:%M까지')\n",
    "        formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "        return formatted_date\n",
    "    else:\n",
    "        return date_str\n",
    "\n",
    "new_df['마감일'] = new_df['마감일'].apply(format_date)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 근무지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['근무지'] = new_df['근무지'].str.replace('주소 ', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('대한민국 ', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울특별시', '서울')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울시', '서울')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('경기도', '경기')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('제주특별자치도', '제주')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('제주특별자치도', '제주')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('울산광역시', '울산')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('경상북도', '경북')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('부산광역시', '부산')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('인천광역시', '인천')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('대전시', '대전')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('대전광역시', '대전')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('대구광역시', '대구')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 경기', '경기')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('전라남도', '전남')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('인천시', '인천')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('Level ', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('입니다', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('입니다', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('대구 대전', '대전')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 06237', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace(' 서울', '서울')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace(r'서울 \\(06159\\)\\s*', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace(r'서울 13449\\)\\s*', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace(r'\\(07807\\)\\s*', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace(r'\\(08380\\)\\s*', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace(r'\\(06159\\)\\s*', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace(r'\\[본사\\]\\s*', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('\\n·', '')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace(r'^\\(\\d+\\)\\s*', '', regex=True)\n",
    "new_df['근무지'] = new_df['근무지'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('연남로13길9', '서울 마포구 연남로13길9', regex=True)\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('광주 광주광역시', '광주')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 논현로', '서울 강남구 논현로')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 왕십리로', '서울 성동구 왕십리로')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 서초동', '서울 서초구 서초동')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 마포대로', '서울 마포구 마포대로')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 반포대로', '서울 서초구 반포대로')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 원격 근무', '원격 근무')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 개포로', '서울 강남구 개포로')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 삼성로', '서울 강남구 삼성로')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 양재동', '서울 서초구 양재동')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('경기 금토로', '경기 성남시 수정구 금토로')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('대전 가정북로', '대전 유성구 가정북로')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 강남대로 156', '서울 서초구 강남대로 156')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('경기 판교', '경기 성남시 분당구 판교동')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('대구 대구시내', '대구 중구 동성로')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 양화로', '서울 마포구 양화로')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 발산역', '서울 강서구 마곡동')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 양재역', '서울 서초구 양재역')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 서울', '서울')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 선릉로', '서울 강남구 선릉로')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 테헤란로', '서울 강남구 테헤란로')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 삼성동', '서울 강남구 삼성동')\n",
    "new_df['근무지'] = new_df['근무지'].str.replace('서울 양재동', '서울 서초구 양재동')\n",
    "\n",
    "new_df['근무지'] = new_df['근무지'].apply(lambda x: x.split(' ', 1)[1] if len(x.split(' ')) > 1 and x.split(' ')[0] == x.split(' ')[1] else x)\n",
    "\n",
    "new_df.loc[new_df['근무지'].str.contains('Seoul, Republic of Korea', na=False), '근무지'] = None\n",
    "new_df.loc[new_df['근무지'].str.contains('서울 대치로 223', na=False), '근무지'] = None\n",
    "new_df.loc[new_df['근무지'].str.contains('원격 근무', na=False), '근무지'] = None\n",
    "new_df.loc[new_df['근무지'].str.contains('onetkorea137@gmail.com', na=False), '근무지'] = None\n",
    "\n",
    "new_df['근무지'] = new_df['근무지'].astype(str)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기존 데이터와 new_df 비교"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new_df에만 있는 회사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_company_list = pd.Index(new_df['회사명'].unique()).difference(now_df['회사명'].unique()).tolist()\n",
    "new_company_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회사명과 평점으로 구성된 데이터 프레임\n",
    "company_star_df = pd.DataFrame(columns=['회사명', '평점'])\n",
    "\n",
    "# 크롤링 시작\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get('https://www.jobplanet.co.kr/search?query=+&category=search_new&search_keyword_hint_id=&_rs_con=seach&_rs_act=keyword_search')\n",
    "time.sleep(3)  # 3초 동안 대기\n",
    "\n",
    "for company in new_company_list:\n",
    "    # 검색 버튼 누르기\n",
    "    input_button = driver.find_element(By.XPATH, '//*[@id=\"search_bar_search_query\"]')\n",
    "    input_button.send_keys(company)\n",
    "    time.sleep(2)\n",
    "    star=0.0\n",
    "\n",
    "    elements = driver.find_elements(By.CSS_SELECTOR, 'ul > li.company')\n",
    "    if len(elements)==0:\n",
    "        pass\n",
    "    else:\n",
    "        submit_button=driver.find_element(By.CSS_SELECTOR, '#search_form > div > button')\n",
    "        submit_button.click()\n",
    "        time.sleep(2)  # 2초 동안 대기\n",
    "        if len(elements)==1:\n",
    "            star=driver.find_element(By.XPATH,'//*[@id=\"mainContents\"]/div[1]/div/div[2]/div[1]/div/span[3]').text        \n",
    "        else:\n",
    "            cards = driver.find_elements(By.CLASS_NAME, 'result_card')\n",
    "            for card in cards:\n",
    "                jp_company = card.text.split()[0].replace(\"(주)\", \"\")\n",
    "                if company == jp_company:\n",
    "                    star = card.text.split()[2]\n",
    "                    break\n",
    "\n",
    "    print(company,star)    \n",
    "    company_star_df.loc[len(company_star_df)] = [company, star]\n",
    "    # 검색창 지우기\n",
    "    input_button = driver.find_element(By.XPATH, '//*[@id=\"search_bar_search_query\"]')  # input_button 웹 요소를 다시 찾음\n",
    "    input_button.clear()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df에 해당 데이터 추가\n",
    "new_df = new_df.merge(company_star_df, on='회사명', how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 회사명이 기존 데이터와 신규 데이터에 모두 있는 경우\n",
    "intersection = pd.Series(list(set(now_df['회사명'].unique()) & set(new_df['회사명'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_link_starts = ['https://www.wanted.co.kr/', 'https://programmers.co.kr', 'https://www.jumpit.co.kr/']\n",
    "\n",
    "for company in intersection:\n",
    "    now_group = now_df[now_df['회사명'] == company]\n",
    "    new_group = new_df[new_df['회사명'] == company]\n",
    "    \n",
    "    for _, now_row in now_group.iterrows():\n",
    "        now_job_title = now_row['공고명'].replace(\" \", \"\")\n",
    "        \n",
    "        for _, new_row in new_group.iterrows():\n",
    "            new_job_title = new_row['공고명'].replace(\" \", \"\")\n",
    "            \n",
    "            if now_job_title == new_job_title or now_job_title in new_job_title or new_job_title in now_job_title:\n",
    "                matching_links = []\n",
    "                if now_row['링크'].startswith('http'):\n",
    "                    matching_links.append(now_row['링크'])\n",
    "                if new_row['링크'].startswith('http'):\n",
    "                    matching_links.append(new_row['링크'])\n",
    "                \n",
    "                if len(matching_links) > 1:\n",
    "                    same_start = True\n",
    "                    for i in range(1, len(matching_links)):\n",
    "                        if not matching_links[i].startswith(matching_links[0]):\n",
    "                            same_start = False\n",
    "                            break\n",
    "                    \n",
    "                    if same_start:\n",
    "                        continue\n",
    "                \n",
    "                if any(link.startswith(start) for link in matching_links for start in allowed_link_starts):\n",
    "                    continue\n",
    "                \n",
    "                new_df.drop(new_row.name, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평점 넣기\n",
    "for company in intersection:\n",
    "    now_rating = now_df.loc[now_df['회사명'] == company, '평점'].iloc[0]\n",
    "    new_df.loc[new_df['회사명'] == company, '평점'] = now_rating"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지역 추가 및 new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['지역']=new_df['근무지'].apply(lambda address: \" \".join(address.split(\" \")[:2]))\n",
    "new_df.to_csv(r'C:\\Users\\Playdata\\Desktop\\new_df.csv', index=True, encoding='cp949')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
